2026-01-22 23:15:30,998 - Experiment Config: {'model': 'sam_dinov2_vitb_lora_multi_output_input', 'data_path': '/mnt/nvme1n1/lululemon/xjj/datasets/resized/gazefollow_extended', 'ckpt_save_dir': './experiments', 'wandb_project': 'sam_dinov2_vitb_lora_multi_output_input', 'exp_name': 'train_sam_dinov2_lora_prompt_gazefollow_multi_output_input', 'log_iter': 10, 'max_epochs': 15, 'batch_size': 60, 'lr': 0.001, 'n_workers': 8}
2026-01-22 23:15:37,981 - Learnable parameters: 5959400
2026-01-22 23:15:43,691 - 
[Epoch 0 Training]
2026-01-22 23:15:46,718 - Iter 0/1891, Loss=26.7907, Text Loss=7.9152, Seg Loss=0.9647, Direction Loss=2.7947, Loss=26.7907
2026-01-22 23:15:56,548 - Iter 10/1891, Loss=5.5466, Text Loss=3.2710, Seg Loss=0.2028, Direction Loss=1.9796, Loss=5.5466
2026-01-22 23:16:06,356 - Iter 20/1891, Loss=4.5242, Text Loss=2.5527, Seg Loss=0.2358, Direction Loss=1.6538, Loss=4.5242
2026-01-22 23:16:16,147 - Iter 30/1891, Loss=4.0790, Text Loss=2.2093, Seg Loss=0.1611, Direction Loss=1.6288, Loss=4.0790
2026-01-22 23:16:26,142 - Iter 40/1891, Loss=4.1919, Text Loss=2.2370, Seg Loss=0.1982, Direction Loss=1.6832, Loss=4.1919
2026-01-22 23:16:36,086 - Iter 50/1891, Loss=4.1761, Text Loss=2.1676, Seg Loss=0.1964, Direction Loss=1.7393, Loss=4.1761
2026-01-22 23:16:46,028 - Iter 60/1891, Loss=4.2794, Text Loss=2.1602, Seg Loss=0.1451, Direction Loss=1.9038, Loss=4.2794
2026-01-22 23:16:55,902 - Iter 70/1891, Loss=3.8629, Text Loss=2.0234, Seg Loss=0.1864, Direction Loss=1.5834, Loss=3.8629
2026-01-22 23:17:05,640 - Iter 80/1891, Loss=4.3468, Text Loss=1.9856, Seg Loss=0.2223, Direction Loss=2.0671, Loss=4.3468
2026-01-22 23:17:15,406 - Iter 90/1891, Loss=4.0148, Text Loss=1.9892, Seg Loss=0.1573, Direction Loss=1.7963, Loss=4.0148
2026-01-22 23:17:25,150 - Iter 100/1891, Loss=3.8431, Text Loss=1.8684, Seg Loss=0.2265, Direction Loss=1.6782, Loss=3.8431
2026-01-22 23:17:34,953 - Iter 110/1891, Loss=3.9173, Text Loss=2.0489, Seg Loss=0.1289, Direction Loss=1.6679, Loss=3.9173
2026-01-22 23:17:44,917 - Iter 120/1891, Loss=4.0764, Text Loss=1.9594, Seg Loss=0.2482, Direction Loss=1.7955, Loss=4.0764
2026-01-22 23:17:54,670 - Iter 130/1891, Loss=3.7936, Text Loss=2.0114, Seg Loss=0.1353, Direction Loss=1.5757, Loss=3.7936
2026-01-22 23:18:04,621 - Iter 140/1891, Loss=3.6248, Text Loss=1.8917, Seg Loss=0.2064, Direction Loss=1.4549, Loss=3.6248
2026-01-22 23:18:14,505 - Iter 150/1891, Loss=3.7729, Text Loss=1.9658, Seg Loss=0.1375, Direction Loss=1.5991, Loss=3.7729
2026-01-22 23:18:24,333 - Iter 160/1891, Loss=3.6350, Text Loss=1.9154, Seg Loss=0.1755, Direction Loss=1.4736, Loss=3.6350
2026-01-22 23:18:34,129 - Iter 170/1891, Loss=3.7855, Text Loss=2.0170, Seg Loss=0.2015, Direction Loss=1.4960, Loss=3.7855
2026-01-22 23:18:43,819 - Iter 180/1891, Loss=3.5125, Text Loss=1.9178, Seg Loss=0.1661, Direction Loss=1.3565, Loss=3.5125
2026-01-22 23:18:53,527 - Iter 190/1891, Loss=3.6812, Text Loss=1.9698, Seg Loss=0.2522, Direction Loss=1.3897, Loss=3.6812
2026-01-22 23:19:03,234 - Iter 200/1891, Loss=3.5041, Text Loss=1.8837, Seg Loss=0.1565, Direction Loss=1.3932, Loss=3.5041
2026-01-22 23:19:12,875 - Iter 210/1891, Loss=3.9284, Text Loss=2.0961, Seg Loss=0.1600, Direction Loss=1.6025, Loss=3.9284
