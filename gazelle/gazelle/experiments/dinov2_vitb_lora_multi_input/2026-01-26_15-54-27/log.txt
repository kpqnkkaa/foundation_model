2026-01-26 15:54:27,974 - Experiment Config: {'model': 'dinov2_vitb_lora_multi_input', 'data_path': '/mnt/nvme1n1/lululemon/xjj/datasets/resized/gazefollow_extended', 'ckpt_save_dir': './experiments', 'wandb_project': 'dinov2_vitb_lora_multi_input', 'exp_name': 'dinov2_vitb_lora_multi_input', 'log_iter': 10, 'max_epochs': 15, 'batch_size': 60, 'lr': 0.001, 'n_workers': 8}
2026-01-26 15:54:35,906 - Learnable parameters: 7537632
2026-01-26 15:54:42,483 - 
[Epoch 0 Training]
2026-01-26 15:54:46,799 - Iter 0/1891, Loss=0.6698, Loss=0.6698
2026-01-26 15:54:55,067 - Iter 10/1891, Loss=0.0922, Loss=0.0922
2026-01-26 15:55:02,750 - Iter 20/1891, Loss=0.0674, Loss=0.0674
2026-01-26 15:55:10,253 - Iter 30/1891, Loss=0.0595, Loss=0.0595
2026-01-26 15:55:17,359 - Iter 40/1891, Loss=0.0576, Loss=0.0576
2026-01-26 15:55:24,449 - Iter 50/1891, Loss=0.0550, Loss=0.0550
2026-01-26 15:55:32,325 - Iter 60/1891, Loss=0.0560, Loss=0.0560
2026-01-26 15:55:40,011 - Iter 70/1891, Loss=0.0544, Loss=0.0544
2026-01-26 15:55:47,174 - Iter 80/1891, Loss=0.0519, Loss=0.0519
2026-01-26 15:55:54,580 - Iter 90/1891, Loss=0.0525, Loss=0.0525
2026-01-26 15:56:02,084 - Iter 100/1891, Loss=0.0522, Loss=0.0522
2026-01-26 15:56:09,530 - Iter 110/1891, Loss=0.0552, Loss=0.0552
2026-01-26 15:56:16,616 - Iter 120/1891, Loss=0.0522, Loss=0.0522
2026-01-26 15:56:24,207 - Iter 130/1891, Loss=0.0553, Loss=0.0553
2026-01-26 15:56:31,696 - Iter 140/1891, Loss=0.0546, Loss=0.0546
2026-01-26 15:56:39,181 - Iter 150/1891, Loss=0.0522, Loss=0.0522
2026-01-26 15:56:46,942 - Iter 160/1891, Loss=0.0542, Loss=0.0542
2026-01-26 15:56:54,173 - Iter 170/1891, Loss=0.0487, Loss=0.0487
2026-01-26 15:57:01,705 - Iter 180/1891, Loss=0.0554, Loss=0.0554
2026-01-26 15:57:09,301 - Iter 190/1891, Loss=0.0503, Loss=0.0503
2026-01-26 15:57:17,120 - Iter 200/1891, Loss=0.0549, Loss=0.0549
