2026-01-22 01:23:53,523 - Experiment Config: {'model': 'sam_dinov2_vitb_lora_multi_input_inout', 'data_path': '/mnt/nvme1n1/lululemon/xjj/datasets/resized/gazefollow_extended', 'ckpt_save_dir': './experiments', 'wandb_project': 'sam_dinov2_vitb_lora_multi_input_inout', 'exp_name': 'train_sam_dinov2_lora_prompt_gazefollow_multi_input', 'log_iter': 10, 'max_epochs': 15, 'batch_size': 60, 'lr': 0.001, 'n_workers': 8}
2026-01-22 01:23:58,888 - Learnable parameters: 7497217
2026-01-22 01:24:04,163 - 
[Epoch 0 Training]
2026-01-22 01:24:07,698 - Iter 0/1891, Loss=0.6875, Loss=0.6875
2026-01-22 01:24:14,250 - Iter 10/1891, Loss=0.1123, Loss=0.1123
2026-01-22 01:24:20,447 - Iter 20/1891, Loss=0.0671, Loss=0.0671
2026-01-22 01:24:26,546 - Iter 30/1891, Loss=0.0630, Loss=0.0630
2026-01-22 01:24:32,647 - Iter 40/1891, Loss=0.0550, Loss=0.0550
2026-01-22 01:24:38,733 - Iter 50/1891, Loss=0.0547, Loss=0.0547
2026-01-22 01:24:45,359 - Iter 60/1891, Loss=0.0536, Loss=0.0536
2026-01-22 01:24:51,424 - Iter 70/1891, Loss=0.0535, Loss=0.0535
2026-01-22 01:24:57,543 - Iter 80/1891, Loss=0.0519, Loss=0.0519
2026-01-22 01:25:03,626 - Iter 90/1891, Loss=0.0521, Loss=0.0521
2026-01-22 01:25:09,734 - Iter 100/1891, Loss=0.0561, Loss=0.0561
2026-01-22 01:25:15,825 - Iter 110/1891, Loss=0.0487, Loss=0.0487
2026-01-22 01:25:21,892 - Iter 120/1891, Loss=0.0527, Loss=0.0527
2026-01-22 01:25:28,029 - Iter 130/1891, Loss=0.0529, Loss=0.0529
2026-01-22 01:25:34,610 - Iter 140/1891, Loss=0.0515, Loss=0.0515
2026-01-22 01:25:40,649 - Iter 150/1891, Loss=0.0544, Loss=0.0544
