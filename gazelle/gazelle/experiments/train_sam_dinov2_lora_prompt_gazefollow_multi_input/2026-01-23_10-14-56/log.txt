2026-01-23 10:14:56,003 - Experiment Config: {'model': 'sam_sam_vitb', 'data_path': '/mnt/nvme1n1/lululemon/xjj/datasets/resized/gazefollow_extended', 'ckpt_save_dir': './experiments', 'wandb_project': 'sam_dinov2_vitb_lora_multi_input', 'exp_name': 'train_sam_dinov2_lora_prompt_gazefollow_multi_input', 'log_iter': 10, 'max_epochs': 15, 'batch_size': 60, 'lr': 0.001, 'n_workers': 8}
2026-01-23 10:14:58,264 - Learnable parameters: 3626188
2026-01-23 10:15:04,946 - 
[Epoch 0 Training]
2026-01-23 10:15:07,084 - Iter 0/1891, Loss=0.6913, Loss=0.6913
2026-01-23 10:15:10,840 - Iter 10/1891, Loss=0.1925, Loss=0.1925
2026-01-23 10:15:14,618 - Iter 20/1891, Loss=0.0819, Loss=0.0819
2026-01-23 10:15:18,382 - Iter 30/1891, Loss=0.0738, Loss=0.0738
2026-01-23 10:15:22,157 - Iter 40/1891, Loss=0.0711, Loss=0.0711
2026-01-23 10:15:26,010 - Iter 50/1891, Loss=0.0745, Loss=0.0745
2026-01-23 10:15:29,815 - Iter 60/1891, Loss=0.0735, Loss=0.0735
2026-01-23 10:15:33,546 - Iter 70/1891, Loss=0.0687, Loss=0.0687
2026-01-23 10:15:37,337 - Iter 80/1891, Loss=0.0713, Loss=0.0713
2026-01-23 10:15:41,114 - Iter 90/1891, Loss=0.0710, Loss=0.0710
2026-01-23 10:15:44,918 - Iter 100/1891, Loss=0.0711, Loss=0.0711
2026-01-23 10:15:48,664 - Iter 110/1891, Loss=0.0702, Loss=0.0702
2026-01-23 10:15:52,435 - Iter 120/1891, Loss=0.0718, Loss=0.0718
2026-01-23 10:15:56,240 - Iter 130/1891, Loss=0.0703, Loss=0.0703
2026-01-23 10:16:00,021 - Iter 140/1891, Loss=0.0715, Loss=0.0715
2026-01-23 10:16:03,757 - Iter 150/1891, Loss=0.0720, Loss=0.0720
2026-01-23 10:16:07,413 - Iter 160/1891, Loss=0.0711, Loss=0.0711
2026-01-23 10:16:11,098 - Iter 170/1891, Loss=0.0703, Loss=0.0703
2026-01-23 10:16:14,799 - Iter 180/1891, Loss=0.0714, Loss=0.0714
2026-01-23 10:16:18,539 - Iter 190/1891, Loss=0.0707, Loss=0.0707
2026-01-23 10:16:22,236 - Iter 200/1891, Loss=0.0701, Loss=0.0701
