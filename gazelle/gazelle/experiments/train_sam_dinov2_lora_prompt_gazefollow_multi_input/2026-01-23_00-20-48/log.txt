2026-01-23 00:20:48,856 - Experiment Config: {'model': 'sam_dinov2_vitb_lora', 'data_path': '/mnt/nvme1n1/lululemon/xjj/datasets/resized/gazefollow_extended', 'ckpt_save_dir': './experiments', 'wandb_project': 'sam_dinov2_vitb_lora_multi_input', 'exp_name': 'train_sam_dinov2_lora_prompt_gazefollow_multi_input', 'log_iter': 10, 'max_epochs': 15, 'batch_size': 60, 'lr': 0.001, 'n_workers': 8}
2026-01-23 00:23:02,950 - Learnable parameters: 4940640
2026-01-23 00:23:08,718 - 
[Epoch 0 Training]
2026-01-23 00:23:11,443 - Iter 0/1891, Loss=2.2998, Loss=2.2998
2026-01-23 00:23:19,798 - Iter 10/1891, Loss=1.2891, Loss=1.2891
2026-01-23 00:23:28,094 - Iter 20/1891, Loss=1.3320, Loss=1.3320
2026-01-23 00:23:36,434 - Iter 30/1891, Loss=1.3228, Loss=1.3228
2026-01-23 00:23:44,736 - Iter 40/1891, Loss=1.2819, Loss=1.2819
2026-01-23 00:23:53,067 - Iter 50/1891, Loss=1.3430, Loss=1.3430
2026-01-23 00:24:01,370 - Iter 60/1891, Loss=1.3349, Loss=1.3349
2026-01-23 00:24:09,682 - Iter 70/1891, Loss=1.3115, Loss=1.3115
2026-01-23 00:24:17,963 - Iter 80/1891, Loss=1.3145, Loss=1.3145
2026-01-23 00:24:26,265 - Iter 90/1891, Loss=1.2979, Loss=1.2979
2026-01-23 00:24:34,544 - Iter 100/1891, Loss=1.3362, Loss=1.3362
2026-01-23 00:24:42,795 - Iter 110/1891, Loss=1.3023, Loss=1.3023
2026-01-23 00:24:51,102 - Iter 120/1891, Loss=1.2889, Loss=1.2889
2026-01-23 00:24:59,413 - Iter 130/1891, Loss=1.3035, Loss=1.3035
2026-01-23 00:25:07,702 - Iter 140/1891, Loss=1.2898, Loss=1.2898
2026-01-23 00:25:16,007 - Iter 150/1891, Loss=1.2962, Loss=1.2962
2026-01-23 00:25:24,306 - Iter 160/1891, Loss=1.3429, Loss=1.3429
2026-01-23 00:25:32,612 - Iter 170/1891, Loss=1.3488, Loss=1.3488
2026-01-23 00:25:40,889 - Iter 180/1891, Loss=1.2939, Loss=1.2939
2026-01-23 00:25:49,094 - Iter 190/1891, Loss=1.3210, Loss=1.3210
2026-01-23 00:25:57,376 - Iter 200/1891, Loss=1.3464, Loss=1.3464
2026-01-23 00:26:05,641 - Iter 210/1891, Loss=1.3099, Loss=1.3099
2026-01-23 00:26:13,898 - Iter 220/1891, Loss=1.2942, Loss=1.2942
2026-01-23 00:26:22,179 - Iter 230/1891, Loss=1.2923, Loss=1.2923
2026-01-23 00:26:30,480 - Iter 240/1891, Loss=1.3209, Loss=1.3209
2026-01-23 00:26:38,901 - Iter 250/1891, Loss=1.3270, Loss=1.3270
2026-01-23 00:26:47,233 - Iter 260/1891, Loss=1.3161, Loss=1.3161
2026-01-23 00:26:55,497 - Iter 270/1891, Loss=1.3227, Loss=1.3227
2026-01-23 00:27:03,801 - Iter 280/1891, Loss=1.3089, Loss=1.3089
2026-01-23 00:27:12,052 - Iter 290/1891, Loss=1.2857, Loss=1.2857
2026-01-23 00:27:20,391 - Iter 300/1891, Loss=1.2699, Loss=1.2699
2026-01-23 00:27:28,687 - Iter 310/1891, Loss=1.2859, Loss=1.2859
2026-01-23 00:27:36,976 - Iter 320/1891, Loss=1.3448, Loss=1.3448
2026-01-23 00:27:45,263 - Iter 330/1891, Loss=1.3332, Loss=1.3332
2026-01-23 00:27:53,491 - Iter 340/1891, Loss=1.3212, Loss=1.3212
2026-01-23 00:28:01,723 - Iter 350/1891, Loss=1.3388, Loss=1.3388
2026-01-23 00:28:10,020 - Iter 360/1891, Loss=1.3024, Loss=1.3024
2026-01-23 00:28:18,302 - Iter 370/1891, Loss=1.3324, Loss=1.3324
2026-01-23 00:28:26,613 - Iter 380/1891, Loss=1.3141, Loss=1.3141
2026-01-23 00:28:34,943 - Iter 390/1891, Loss=1.3184, Loss=1.3184
2026-01-23 00:28:43,197 - Iter 400/1891, Loss=1.3022, Loss=1.3022
2026-01-23 00:28:51,395 - Iter 410/1891, Loss=1.3392, Loss=1.3392
2026-01-23 00:28:59,672 - Iter 420/1891, Loss=1.3313, Loss=1.3313
2026-01-23 00:29:07,953 - Iter 430/1891, Loss=1.3113, Loss=1.3113
2026-01-23 00:29:16,214 - Iter 440/1891, Loss=1.3080, Loss=1.3080
2026-01-23 00:29:24,524 - Iter 450/1891, Loss=1.3441, Loss=1.3441
2026-01-23 00:29:32,785 - Iter 460/1891, Loss=1.3354, Loss=1.3354
2026-01-23 00:29:41,054 - Iter 470/1891, Loss=1.3264, Loss=1.3264
2026-01-23 00:29:49,340 - Iter 480/1891, Loss=1.3260, Loss=1.3260
2026-01-23 00:29:57,630 - Iter 490/1891, Loss=1.3271, Loss=1.3271
2026-01-23 00:30:05,962 - Iter 500/1891, Loss=1.2935, Loss=1.2935
2026-01-23 00:30:14,221 - Iter 510/1891, Loss=1.3087, Loss=1.3087
2026-01-23 00:30:22,549 - Iter 520/1891, Loss=1.3001, Loss=1.3001
2026-01-23 00:30:30,861 - Iter 530/1891, Loss=1.3211, Loss=1.3211
2026-01-23 00:30:39,185 - Iter 540/1891, Loss=1.3122, Loss=1.3122
