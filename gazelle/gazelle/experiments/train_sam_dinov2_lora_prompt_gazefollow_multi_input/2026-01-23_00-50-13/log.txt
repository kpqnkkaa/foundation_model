2026-01-23 00:50:13,764 - Experiment Config: {'model': 'sam_sam_vitb', 'data_path': '/mnt/nvme1n1/lululemon/xjj/datasets/resized/gazefollow_extended', 'ckpt_save_dir': './experiments', 'wandb_project': 'sam_dinov2_vitb_lora_multi_input', 'exp_name': 'train_sam_dinov2_lora_prompt_gazefollow_multi_input', 'log_iter': 10, 'max_epochs': 15, 'batch_size': 60, 'lr': 0.001, 'n_workers': 8}
2026-01-23 00:50:16,438 - Learnable parameters: 3990496
2026-01-23 00:50:22,731 - 
[Epoch 0 Training]
2026-01-23 00:50:24,742 - Iter 0/1891, Loss=1.2754, Loss=1.2754
2026-01-23 00:50:27,875 - Iter 10/1891, Loss=0.0741, Loss=0.0741
2026-01-23 00:50:31,105 - Iter 20/1891, Loss=0.0698, Loss=0.0698
2026-01-23 00:50:34,231 - Iter 30/1891, Loss=0.0698, Loss=0.0698
2026-01-23 00:50:37,401 - Iter 40/1891, Loss=0.0692, Loss=0.0692
2026-01-23 00:50:40,567 - Iter 50/1891, Loss=0.0705, Loss=0.0705
2026-01-23 00:50:43,740 - Iter 60/1891, Loss=0.0705, Loss=0.0705
2026-01-23 00:50:46,908 - Iter 70/1891, Loss=0.0713, Loss=0.0713
2026-01-23 00:50:50,106 - Iter 80/1891, Loss=0.0688, Loss=0.0688
2026-01-23 00:50:53,231 - Iter 90/1891, Loss=0.0704, Loss=0.0704
2026-01-23 00:50:56,353 - Iter 100/1891, Loss=0.0669, Loss=0.0669
2026-01-23 00:50:59,469 - Iter 110/1891, Loss=0.0700, Loss=0.0700
2026-01-23 00:51:02,623 - Iter 120/1891, Loss=0.0679, Loss=0.0679
2026-01-23 00:51:05,781 - Iter 130/1891, Loss=0.0701, Loss=0.0701
2026-01-23 00:51:08,951 - Iter 140/1891, Loss=0.0699, Loss=0.0699
2026-01-23 00:51:12,060 - Iter 150/1891, Loss=0.0678, Loss=0.0678
2026-01-23 00:51:15,183 - Iter 160/1891, Loss=0.0705, Loss=0.0705
2026-01-23 00:51:18,293 - Iter 170/1891, Loss=0.0687, Loss=0.0687
2026-01-23 00:51:21,391 - Iter 180/1891, Loss=0.0689, Loss=0.0689
2026-01-23 00:51:24,501 - Iter 190/1891, Loss=0.0700, Loss=0.0700
2026-01-23 00:51:27,597 - Iter 200/1891, Loss=0.0687, Loss=0.0687
2026-01-23 00:51:30,768 - Iter 210/1891, Loss=0.0678, Loss=0.0678
2026-01-23 00:51:33,975 - Iter 220/1891, Loss=0.0685, Loss=0.0685
2026-01-23 00:51:37,105 - Iter 230/1891, Loss=0.0697, Loss=0.0697
2026-01-23 00:51:40,318 - Iter 240/1891, Loss=0.0700, Loss=0.0700
2026-01-23 00:51:43,514 - Iter 250/1891, Loss=0.0692, Loss=0.0692
2026-01-23 00:51:46,701 - Iter 260/1891, Loss=0.0676, Loss=0.0676
2026-01-23 00:51:49,894 - Iter 270/1891, Loss=0.0686, Loss=0.0686
2026-01-23 00:51:53,082 - Iter 280/1891, Loss=0.0677, Loss=0.0677
