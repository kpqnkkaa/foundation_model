2026-01-21 19:08:01,687 - Experiment Config: {'model': 'sam_dinov2_vitb_lora', 'data_path': '/mnt/nvme1n1/lululemon/xjj/datasets/resized/gazefollow_extended', 'ckpt_save_dir': './experiments', 'wandb_project': 'sam_sam_vitb_lora_multi_input', 'exp_name': 'train_sam_dinov2_lora_prompt_gazefollow_multi_input', 'log_iter': 10, 'max_epochs': 15, 'batch_size': 60, 'lr': 0.001, 'n_workers': 8}
2026-01-21 19:08:06,070 - Learnable parameters: 6972160
2026-01-21 19:08:11,572 - 
[Epoch 0 Training]
2026-01-21 19:08:14,012 - Iter 0/1891, Loss=0.7120
2026-01-21 19:08:22,806 - Iter 10/1891, Loss=0.0739
2026-01-21 19:08:31,549 - Iter 20/1891, Loss=0.0602
2026-01-21 19:08:40,359 - Iter 30/1891, Loss=0.0587
2026-01-21 19:08:49,061 - Iter 40/1891, Loss=0.0537
2026-01-21 19:08:57,815 - Iter 50/1891, Loss=0.0548
2026-01-21 19:09:06,598 - Iter 60/1891, Loss=0.0536
2026-01-21 19:09:15,386 - Iter 70/1891, Loss=0.0527
2026-01-21 19:09:24,144 - Iter 80/1891, Loss=0.0536
2026-01-21 19:09:32,896 - Iter 90/1891, Loss=0.0518
2026-01-21 19:09:41,637 - Iter 100/1891, Loss=0.0490
2026-01-21 19:09:50,375 - Iter 110/1891, Loss=0.0507
2026-01-21 19:09:59,102 - Iter 120/1891, Loss=0.0547
2026-01-21 19:10:07,815 - Iter 130/1891, Loss=0.0498
2026-01-21 19:10:16,553 - Iter 140/1891, Loss=0.0517
2026-01-21 19:10:25,326 - Iter 150/1891, Loss=0.0482
