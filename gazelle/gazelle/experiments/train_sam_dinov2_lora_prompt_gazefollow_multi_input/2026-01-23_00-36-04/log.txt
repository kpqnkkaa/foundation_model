2026-01-23 00:36:04,051 - Experiment Config: {'model': 'sam_dinov2_vitb', 'data_path': '/mnt/nvme1n1/lululemon/xjj/datasets/resized/gazefollow_extended', 'ckpt_save_dir': './experiments', 'wandb_project': 'sam_dinov2_vitb_lora_multi_input', 'exp_name': 'train_sam_dinov2_lora_prompt_gazefollow_multi_input', 'log_iter': 10, 'max_epochs': 15, 'batch_size': 60, 'lr': 0.001, 'n_workers': 8}
2026-01-23 00:38:18,507 - Learnable parameters: 4645728
2026-01-23 00:38:23,812 - 
[Epoch 0 Training]
2026-01-23 00:38:25,922 - Iter 0/1891, Loss=6.4406, Loss=6.4406
2026-01-23 00:38:29,658 - Iter 10/1891, Loss=1.3445, Loss=1.3445
2026-01-23 00:38:33,508 - Iter 20/1891, Loss=1.3188, Loss=1.3188
2026-01-23 00:38:37,454 - Iter 30/1891, Loss=1.3020, Loss=1.3020
2026-01-23 00:38:41,273 - Iter 40/1891, Loss=1.3418, Loss=1.3418
2026-01-23 00:38:45,132 - Iter 50/1891, Loss=1.3144, Loss=1.3144
2026-01-23 00:38:48,980 - Iter 60/1891, Loss=1.2969, Loss=1.2969
2026-01-23 00:38:52,900 - Iter 70/1891, Loss=1.3601, Loss=1.3601
2026-01-23 00:38:56,768 - Iter 80/1891, Loss=1.3053, Loss=1.3053
2026-01-23 00:39:00,620 - Iter 90/1891, Loss=1.3126, Loss=1.3126
2026-01-23 00:39:04,461 - Iter 100/1891, Loss=1.3164, Loss=1.3164
2026-01-23 00:39:08,231 - Iter 110/1891, Loss=1.3151, Loss=1.3151
2026-01-23 00:39:12,109 - Iter 120/1891, Loss=1.3263, Loss=1.3263
2026-01-23 00:39:15,968 - Iter 130/1891, Loss=1.3088, Loss=1.3088
2026-01-23 00:39:19,732 - Iter 140/1891, Loss=1.3406, Loss=1.3406
2026-01-23 00:39:23,514 - Iter 150/1891, Loss=1.2942, Loss=1.2942
2026-01-23 00:39:27,326 - Iter 160/1891, Loss=1.3325, Loss=1.3325
2026-01-23 00:39:31,110 - Iter 170/1891, Loss=1.3268, Loss=1.3268
2026-01-23 00:39:34,838 - Iter 180/1891, Loss=1.2943, Loss=1.2943
2026-01-23 00:39:38,529 - Iter 190/1891, Loss=1.2856, Loss=1.2856
2026-01-23 00:39:42,282 - Iter 200/1891, Loss=1.2988, Loss=1.2988
2026-01-23 00:39:46,046 - Iter 210/1891, Loss=1.3161, Loss=1.3161
2026-01-23 00:39:49,962 - Iter 220/1891, Loss=1.2781, Loss=1.2781
2026-01-23 00:39:53,817 - Iter 230/1891, Loss=1.3327, Loss=1.3327
2026-01-23 00:39:57,754 - Iter 240/1891, Loss=1.3174, Loss=1.3174
2026-01-23 00:40:01,636 - Iter 250/1891, Loss=1.3252, Loss=1.3252
2026-01-23 00:40:05,489 - Iter 260/1891, Loss=1.3299, Loss=1.3299
2026-01-23 00:40:09,369 - Iter 270/1891, Loss=1.3047, Loss=1.3047
2026-01-23 00:40:13,256 - Iter 280/1891, Loss=1.3497, Loss=1.3497
2026-01-23 00:40:17,106 - Iter 290/1891, Loss=1.3066, Loss=1.3066
2026-01-23 00:40:21,005 - Iter 300/1891, Loss=1.2839, Loss=1.2839
2026-01-23 00:40:24,793 - Iter 310/1891, Loss=1.3153, Loss=1.3153
2026-01-23 00:40:28,536 - Iter 320/1891, Loss=1.3243, Loss=1.3243
2026-01-23 00:40:32,288 - Iter 330/1891, Loss=1.3273, Loss=1.3273
2026-01-23 00:40:36,055 - Iter 340/1891, Loss=1.2922, Loss=1.2922
2026-01-23 00:40:39,852 - Iter 350/1891, Loss=1.3141, Loss=1.3141
2026-01-23 00:40:43,719 - Iter 360/1891, Loss=1.2859, Loss=1.2859
2026-01-23 00:40:47,495 - Iter 370/1891, Loss=1.3279, Loss=1.3279
2026-01-23 00:40:51,360 - Iter 380/1891, Loss=1.3064, Loss=1.3064
