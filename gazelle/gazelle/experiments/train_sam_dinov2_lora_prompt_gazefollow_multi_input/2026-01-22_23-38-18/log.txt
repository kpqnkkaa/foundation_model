2026-01-22 23:38:18,772 - Experiment Config: {'model': 'sam_sam_vitb_lora', 'data_path': '/mnt/nvme1n1/lululemon/xjj/datasets/resized/gazefollow_extended', 'ckpt_save_dir': './experiments', 'wandb_project': 'sam_dinov2_vitb_lora_multi_input', 'exp_name': 'train_sam_dinov2_lora_prompt_gazefollow_multi_input', 'log_iter': 10, 'max_epochs': 15, 'batch_size': 60, 'lr': 0.001, 'n_workers': 8}
2026-01-22 23:38:21,530 - Learnable parameters: 4686688
2026-01-22 23:38:26,788 - 
[Epoch 0 Training]
2026-01-22 23:38:29,386 - Iter 0/1891, Loss=22.6951, Loss=22.6951
2026-01-22 23:38:35,763 - Iter 10/1891, Loss=0.0825, Loss=0.0825
2026-01-22 23:38:42,156 - Iter 20/1891, Loss=0.0786, Loss=0.0786
2026-01-22 23:38:48,611 - Iter 30/1891, Loss=0.0757, Loss=0.0757
2026-01-22 23:38:55,038 - Iter 40/1891, Loss=0.0747, Loss=0.0747
2026-01-22 23:39:01,463 - Iter 50/1891, Loss=0.0742, Loss=0.0742
2026-01-22 23:39:07,867 - Iter 60/1891, Loss=0.0724, Loss=0.0724
2026-01-22 23:39:14,285 - Iter 70/1891, Loss=0.0727, Loss=0.0727
2026-01-22 23:39:20,683 - Iter 80/1891, Loss=0.0701, Loss=0.0701
2026-01-22 23:39:27,085 - Iter 90/1891, Loss=0.0724, Loss=0.0724
2026-01-22 23:39:33,563 - Iter 100/1891, Loss=0.0717, Loss=0.0717
