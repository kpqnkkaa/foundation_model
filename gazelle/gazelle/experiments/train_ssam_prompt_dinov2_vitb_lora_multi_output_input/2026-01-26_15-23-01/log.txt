2026-01-26 15:23:01,847 - Experiment Config: {'model': 'sam_prompt_dinov2_vitb_lora_multi_output_input', 'data_path': '/mnt/nvme1n1/lululemon/xjj/datasets/resized/gazefollow_extended', 'ckpt_save_dir': './experiments', 'wandb_project': 'sam_prompt_dinov2_vitb_lora_multi_output_input', 'exp_name': 'train_ssam_prompt_dinov2_vitb_lora_multi_output_input', 'log_iter': 10, 'max_epochs': 15, 'batch_size': 60, 'lr': 0.001, 'n_workers': 8}
2026-01-26 15:23:12,916 - Learnable parameters: 8327272
2026-01-26 15:23:20,051 - 
[Epoch 0 Training]
2026-01-26 15:23:26,888 - Iter 0/1891, Loss=11.7074, Text Loss=7.9153, Seg Loss=0.6553, Direction Loss=2.4191, Loss=11.7074
2026-01-26 15:23:41,463 - Iter 10/1891, Loss=5.4486, Text Loss=3.4928, Seg Loss=0.1674, Direction Loss=1.7056, Loss=5.4486
2026-01-26 15:23:55,391 - Iter 20/1891, Loss=4.4325, Text Loss=2.5401, Seg Loss=0.1712, Direction Loss=1.6432, Loss=4.4325
2026-01-26 15:24:08,571 - Iter 30/1891, Loss=4.1606, Text Loss=2.3097, Seg Loss=0.2003, Direction Loss=1.5798, Loss=4.1606
2026-01-26 15:24:23,631 - Iter 40/1891, Loss=3.9397, Text Loss=2.1319, Seg Loss=0.1526, Direction Loss=1.5939, Loss=3.9397
2026-01-26 15:24:38,003 - Iter 50/1891, Loss=3.8521, Text Loss=2.1674, Seg Loss=0.1999, Direction Loss=1.4253, Loss=3.8521
2026-01-26 15:24:51,771 - Iter 60/1891, Loss=3.9662, Text Loss=2.2102, Seg Loss=0.1675, Direction Loss=1.5240, Loss=3.9662
2026-01-26 15:25:06,543 - Iter 70/1891, Loss=3.9909, Text Loss=2.1594, Seg Loss=0.1838, Direction Loss=1.5865, Loss=3.9909
2026-01-26 15:25:21,501 - Iter 80/1891, Loss=3.6415, Text Loss=2.0988, Seg Loss=0.1882, Direction Loss=1.2947, Loss=3.6415
2026-01-26 15:25:36,482 - Iter 90/1891, Loss=3.7222, Text Loss=2.0504, Seg Loss=0.1238, Direction Loss=1.4885, Loss=3.7222
2026-01-26 15:25:50,446 - Iter 100/1891, Loss=3.8398, Text Loss=1.9539, Seg Loss=0.2333, Direction Loss=1.5904, Loss=3.8398
2026-01-26 15:26:04,896 - Iter 110/1891, Loss=3.5640, Text Loss=1.8190, Seg Loss=0.1332, Direction Loss=1.5526, Loss=3.5640
2026-01-26 15:26:18,574 - Iter 120/1891, Loss=3.3055, Text Loss=1.9201, Seg Loss=0.1356, Direction Loss=1.1907, Loss=3.3055
2026-01-26 15:26:32,423 - Iter 130/1891, Loss=3.7493, Text Loss=1.9352, Seg Loss=0.2201, Direction Loss=1.5339, Loss=3.7493
2026-01-26 15:26:45,497 - Iter 140/1891, Loss=3.6887, Text Loss=1.9354, Seg Loss=0.1444, Direction Loss=1.5492, Loss=3.6887
2026-01-26 15:26:59,118 - Iter 150/1891, Loss=3.6038, Text Loss=1.9252, Seg Loss=0.1942, Direction Loss=1.4236, Loss=3.6038
2026-01-26 15:27:12,056 - Iter 160/1891, Loss=3.5652, Text Loss=2.0314, Seg Loss=0.1465, Direction Loss=1.3298, Loss=3.5652
2026-01-26 15:27:26,598 - Iter 170/1891, Loss=3.4471, Text Loss=1.9016, Seg Loss=0.1800, Direction Loss=1.3026, Loss=3.4471
2026-01-26 15:27:40,474 - Iter 180/1891, Loss=3.6614, Text Loss=1.8622, Seg Loss=0.3244, Direction Loss=1.4159, Loss=3.6614
2026-01-26 15:27:54,803 - Iter 190/1891, Loss=3.4132, Text Loss=1.7534, Seg Loss=0.1345, Direction Loss=1.4650, Loss=3.4132
2026-01-26 15:28:08,555 - Iter 200/1891, Loss=3.6289, Text Loss=1.9556, Seg Loss=0.1276, Direction Loss=1.4875, Loss=3.6289
2026-01-26 15:28:22,154 - Iter 210/1891, Loss=3.6348, Text Loss=1.8867, Seg Loss=0.2373, Direction Loss=1.4524, Loss=3.6348
2026-01-26 15:28:36,224 - Iter 220/1891, Loss=3.4473, Text Loss=1.8304, Seg Loss=0.2130, Direction Loss=1.3451, Loss=3.4473
